Technical Specification Document (TSD)
Project: CV Tailoring AI Agent (MVP)
Version: 1.0
Date: May 1, 2025
Authors: [Your Name/Team Name]
1. Introduction
1.1 Purpose
This Technical Specification Document details the technical design and implementation specifications for the CV Tailoring AI Agent MVP. It serves as a technical blueprint for the development team, elaborating on the architecture and data design outlined in the Software Design Document (SDD) and specifying the technologies, algorithms, interfaces, and configurations at a level sufficient for implementation.
1.2 Scope
This document covers the technical specifications for all core components of the MVP, including the specific libraries used, the data structures' implementation details, the algorithms for parsing, research, content generation, and formatting, the technical interfaces with external services (LLM, Vector DB, potentially compiler), the UI implementation approach using Streamlit, state persistence mechanisms, and configuration management.
1.3 Definitions, Acronyms, and Abbreviations
(Inherit definitions from SRS and SDD, Sections 1.3)
ChromaDB: The chosen vector database.
Groq: The chosen LLM API provider.
Jinja2: The chosen templating engine.
Streamlit: The chosen UI framework.
UUID: Universally Unique Identifier.
all-MiniLM-L6-v2: The chosen sentence transformer model for embeddings.
xelatex: The chosen LaTeX compiler executable (if LaTeX output).
1.4 References
Software Requirements Specification (SRS) for the CV Tailering AI Agent (MVP)
Software Design Document (SDD) for the CV Tailoring AI Agent (MVP)
aicvgen (Code folder)
cv_ai_builder_final_template.py (Prototype script)
requirements.txt
prompts_folder
Anas_Akhomach-main-template-en.md
cv_template.md
1.5 Overview
The rest of this document specifies the technology stack, provides a technical view of the architecture, details the technical implementation of data structures, describes the technical design of each component including specific algorithms and interfaces, outlines configuration management, error handling, and the testing strategy.
2. Technology Stack
The MVP will be implemented using the following technologies and libraries, as indicated by requirements.txt and the codebase:
Programming Language: Python 3.x
Core Framework/Orchestration: Custom agent classes (agent_base.py), potentially integrating LangGraph for state machine logic (orchestrator.py).
User Interface: Streamlit (ui.py).
Large Language Model (LLM) API: Groq (llm.py). Specific model: llama3-8b-8192 (or configured equivalent).
Vector Database: ChromaDB (vector_db.py).
Embedding Model: sentence-transformers library using the all-MiniLM-L6-v2 model.
Templating Engine: Jinja2 (template_renderer.py, prototype).
File Handling: Standard Python os and pathlib.
Serialization: json or pickle for state persistence (state_manager.py).
Text Processing/Parsing: Standard Python string methods, re (regex), potentially external libraries for more robust parsing if needed (e.g., markdown-it-py).
Testing: pytest (tests/ folder).
PDF Compilation (if chosen): subprocess module to invoke external xelatex command.
3. System Architecture (Technical View)
The technical architecture implements the logical architecture described in the SDD.
The Manager Agent (orchestrator.py) will implement the workflow as a series of function calls or a state machine controlling the execution of other agent classes.
All agents requiring access to the CV state will interact with a single instance of the State Manager (state_manager.py).
The UI (ui.py) runs on Streamlit's server, interacting with the backend logic (Manager, State Manager) within the same Python process (typical Streamlit architecture). User actions trigger Python function calls.
The Content Writer Agent (content_writer_agent.py) will make HTTP requests to the Groq API endpoint using the groq Python client library wrapped by llm.py.
The Research Agent (research_agent.py) and Vector Store Agent (vector_store_agent.py) will interact with the ChromaDB instance using the chromadb Python client library. The ChromaDB data will persist to disk at a configured path.
Input and output operations, prompt loading (prompts_folder), template loading (cv_template.md, LaTeX template), and state persistence will use standard file system operations.
If LaTeX output is chosen, the Formatter Agent (formatter_agent.py) will use subprocess to call the xelatex command-line executable provided by the underlying operating system's LaTeX distribution.
4. Data Structures (Technical Implementation)
4.1 StructuredCV Data Model
The StructuredCV data model will be implemented using Python dataclasses for clarity and ease of use.
Python
# aicvgen/data_models.py (New file or added to state_manager.py)
import enum
import uuid
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
class ItemStatus(enum.Enum):
    INITIAL = "initial" # Parsed from raw input
    GENERATED = "generated" # Generated by ContentWriter
    USER_EDITED = "user_edited" # Modified directly by user in UI
    TO_REGENERATE = "to_regenerate" # Marked for regeneration by user
    ACCEPTED = "accepted" # Approved by user
    STATIC = "static" # Content from base CV, not tailored by AI
    def __str__(self):
        return self.value # Allows easy string conversion


class ItemType(enum.Enum):
    BULLET_POINT = "bullet_point"
    KEY_QUAL = "key_qual"
    SUMMARY_PARAGRAPH = "summary_paragraph"
    SECTION_TITLE = "section_title"
    SUBSECTION_TITLE = "subsection_title"
    EDUCATION_ENTRY = "education_entry"
    CERTIFICATION_ENTRY = "certification_entry"
    LANGUAGE_ENTRY = "language_entry"
    # Add other types as needed


    def __str__(self):
        return self.value


@dataclass
class Item:
    id: str = field(default_factory=lambda: str(uuid.uuid4())) # Unique ID for granular access
    content: str = ""
    status: ItemStatus = ItemStatus.INITIAL
    item_type: ItemType = ItemType.BULLET_POINT
    metadata: Dict[str, Any] = field(default_factory=dict) # e.g., relevance_score, source_chunk_id, original_line_number
    user_feedback: Optional[str] = None # Optional user comment from UI


    def to_dict(self): # Helper for serialization
         return {k: (v.value if isinstance(v, enum.Enum) else v) for k, v in self.__dict__.items()}


@dataclass
class Subsection:
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    name: str = "" # e.g., "Software Engineer at XYZ Inc."
    items: List[Item] = field(default_factory=list) # e.g., bullet points under this role/project
    metadata: Dict[str, Any] = field(default_factory=dict) # e.g., dates, company, location
    raw_text: str = "" # Original text snippet from parsing


    def to_dict(self):
         return {k: ([item.to_dict() for item in v] if isinstance(v, list) and v and isinstance(v[0], Item) else v) for k, v in self.__dict__.items()}




@dataclass
class Section:
    id: str = field(default_factory=lambda: str(uuid.uuid4()))
    name: str = "" # e.g., "Professional Experience", "Key Qualifications"
    content_type: str = "DYNAMIC" # or "STATIC"
    subsections: List[Subsection] = field(default_factory=list) # For sections like Experience, Projects
    items: List[Item] = field(default_factory=list) # For sections like Key Quals, Education, Languages
    raw_text: str = "" # Original text snippet from parsing
    order: int = 0 # For maintaining section order from the template


    def to_dict(self):
         return {k: ([sub.to_dict() for sub in v] if isinstance(v, list) and v and isinstance(v[0], Subsection) else [item.to_dict() for item in v] if isinstance(v, list) and v and isinstance(v[0], Item) else v) for k, v in self.__dict__.items()}




@dataclass
class StructuredCV:
    id: str = field(default_factory=lambda: str(uuid.uuid4())) # Session ID / CV ID
    sections: List[Section] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict) # e.g., original file paths, timestamp, main_jd_text, similar_jd_texts


    def to_dict(self):
         return {k: ([section.to_dict() for section in v] if isinstance(v, list) and v and isinstance(v[0], Section) else v) for k, v in self.__dict__.items()}


    @staticmethod
    def from_dict(data: Dict[str, Any]) -> 'StructuredCV':
        # Needs inverse logic to reconstruct dataclass objects from dict
        # Handle Enum conversion correctly
        pass # Implementation required
4.2 State Persistence
The StateManager.save_state() method will serialize the StructuredCV object. Given the dataclass structure and potential complexity, pickle might be simpler initially, but JSON with custom encoding/decoding methods (to_dict, from_dict as shown conceptually above) is more portable and human-readable.
The state will be saved to a file named using the StructuredCV.id (session ID) in a designated state directory (e.g., data/sessions/{session_id}/state.pkl or .json).
StateManager.load_state() will deserialize the object from the file.
5. Component Technical Design
5.1 Manager Agent (orchestrator.py)
Dependencies: state_manager.py, all functional agent modules (parser_agent, research_agent, etc.), potentially langchain.graph.
Technical Implementation:
The run_tailoring_session method will initialize the StructuredCV and StateManager.
Workflow logic will be implemented using conditional statements (if/elif/else) or a state machine library. If using LangGraph, define nodes for each agent's execution step and edges defining transitions based on the outcome (e.g., agent returns success status) or explicit calls from the UI handler.
Needs methods to receive UI feedback signals (e.g., handle_ui_action(action_data) where action_data is a dictionary from UI containing item_id, action_type ('accept', 'regenerate', 'edit'), new_content).
Based on action_data, update the StructuredCV via the StateManager (update_item_status, update_item_content).
If action is 'regenerate', trigger the Content Writer specifically for that item_id.
5.2 State Manager (state_manager.py)
Dependencies: The StructuredCV data model definitions (data_models.py or within this file), os, pickle or json.
Technical Implementation:
Hold an instance of StructuredCV.
update_item_content and update_item_status methods will need to traverse the nested StructuredCV object structure using the provided item_id to find and modify the correct Item object. Iterating through sections, subsections, and items will be required.
save_state will serialize _structured_cv to disk.
load_state will deserialize from disk and return the StructuredCV object.
5.3 LLM Wrapper (llm.py)
Dependencies: groq, os.
Technical Implementation:
API key loading: api_key = os.environ.get("GROQ_API_KEY"). Raise an error if not found.
Groq client initialization: client = Groq(api_key=api_key).
chat_completion method: Takes model (string), messages (list of dicts [{'role': 'system', 'content': '...'}, {'role': 'user', 'content': '...'}]), and potentially other parameters (temperature, max_tokens).
Uses a try...except block to handle potential groq.APIError or network errors.
Returns the generated text string from the response object (response.choices[0].message.content).
5.4 Vector Database (vector_db.py) & Vector Store Agent (vector_store_agent.py)
Dependencies: chromadb, sentence_transformers, os.
Technical Implementation:
ChromaDB Initialization: chroma_client = chromadb.PersistentClient(path=config.VECTOR_DB_PATH).
Embedding Model Loading: embedding_model = SentenceTransformer('all-MiniLM-L6-v2'). This model runs locally.
VectorStoreAgent.add_embeddings(texts, metadata_list): Iterates through texts, generates embeddings using embedding_model.encode(), and adds them to the ChromaDB collection using collection.add(embeddings=..., documents=texts, metadata=metadata_list, ids=...). Assign unique IDs (e.g., UUIDs or derived from item IDs).
VectorStoreAgent.query(query_texts, n_results): Generates embeddings for query_texts, calls collection.query(query_embeddings=..., n_results=...). Returns structured results including document text, distance, and metadata.
5.5 Research Agent (research_agent.py)
Dependencies: vector_store_agent.py, state_manager.py (to get JD requirements and CV content).
Technical Implementation:
execute method:
Get parsed JD requirements from the StructuredCV metadata or a specific JD section.
Formulate queries for the VectorStoreAgent.query() method (e.g., each JD requirement as a query).
Call VectorStoreAgent.query().
Process the search results. This might involve filtering by a similarity threshold and grouping results by source CV item ID or section based on metadata.
Structure the output, e.g., a dictionary mapping JD requirement keywords or themes to lists of relevant CV snippets (Item.content) and their IDs. This structured output is passed to the Content Writer.
5.6 Parser Agent (parser_agent.py)
Dependencies: state_manager.py (to create/update StructuredCV), re, typing.
Technical Implementation:
execute method:
Read raw text inputs.
Implement Markdown parsing logic for CV (e.g., regex patterns for ### Section Title, #### Subsection Title, * Bullet point). This needs to handle nested lists and variations.
Create Section, Subsection, and Item objects based on parsed structure, assigning UUIDs as IDs.
Populate content and raw_text fields. Set initial status to INITIAL or STATIC.
Implement basic JD parsing (e.g., regex to find lines or sections containing keywords like "Requirements:", "Skills:", "Responsibilities:"). Extract relevant phrases/keywords.
Return the initial StructuredCV object.
5.7 Content Writer Agent (content_writer_agent.py)
Dependencies: llm.py, state_manager.py, research_agent.py, os, typing.
Technical Implementation:
execute method:
Implement prompt loading: Function to read .md files from prompts_folder.
Implement context building: Function (_build_context) that dynamically generates the prompt string. This function needs access to the full StructuredCV (via State Manager), potentially research findings, and the specific item_id or section name being targeted. It must combine the prompt template with relevant data points from the StructuredCV.
Call llm.py.chat_completion().
Implement robust output parsing (_parse_llm_output). If prompts request JSON, use json.loads within a try...except JSONDecodeError. If text list, use regex or string splitting.
Implement cleaning functions (_clean_output) - port logic from prototype's clean_big_6, clean_json_output.
Update the StructuredCV via StateManager.update_item_content() and update_item_status(ItemStatus.GENERATED).
For regeneration (item_id provided in task instruction), the _build_context logic needs to include the previous generated content and user feedback in the prompt to guide the LLM.
5.8 UI (ui.py)
Dependencies: streamlit, state_manager.py, os, typing.
Technical Implementation:
Use st.session_state to manage UI-specific state (e.g., currently loaded file names, active session ID).
Implement file upload (st.file_uploader).
Call StateManager.load_state or trigger the Orchestrator to start a new session on file upload.
Implement rendering logic: Iterate through StateManager.get_structured_cv().sections. Use st.header, st.subheader.
For dynamic sections/items: Use st.container or st.expander for cards. Display Item.content in an editable st.text_area(value=item.content, key=f'content_{item.id}').
Add buttons: st.button("Accept", key=f'accept_{item.id}', on_click=handle_button_click, args=('accept', item.id)), st.button("Regenerate", key=f'regen_{item.id}', on_click=handle_button_click, args=('regenerate', item.id)).
Implement handle_button_click callback: This function gets the item_id and action. It needs to get the current text from the corresponding st.text_area using its key from st.session_state. Then, it calls a method on the Manager Agent (e.g., manager.handle_user_feedback(item_id, action, new_content)).
Display status indicators next to items based on Item.status.
Add a button to trigger final output generation, calling the Formatter Agent via the Manager.
5.9 Formatter Agent (formatter_agent.py) & Template Renderer (template_renderer.py)
Dependencies: state_manager.py, template_manager.py, jinja2, os, subprocess (if LaTeX).
Technical Implementation:
TemplateManager: Function to read template files (e.g., load_template(name)).
TemplateRenderer.render(structured_cv, template_string):
Initialize Jinja2 environment: env = Environment(loader=...).
Load template: template = env.from_string(template_string).
Prepare data for Jinja2: Convert the StructuredCV object (or relevant parts) into a dictionary structure compatible with the template placeholders. This might involve using the to_dict methods defined in the data model.
Add custom filters if needed (e.g., env.filters['escape_latex'] = escape_latex).
Render: rendered_output = template.render(data_dict).
FormatterAgent.execute:
Get final StructuredCV from StateManager.
Get template string from TemplateManager.
Call TemplateRenderer.render().
If LaTeX output:
Write rendered_output to a .tex file.
Call subprocess.run(['xelatex', 'your_cv.tex'], cwd=output_dir). Handle multiple runs if needed (sometimes required for LaTeX).
Check the return code and output for errors.
(Optional) Clean up auxiliary files (.aux, .log).
If Markdown output: Write rendered_output directly to a .md file.
Return the path to the generated file.
6. Configuration Management
Sensitive information (API keys) SHALL be loaded from environment variables (os.environ.get()).
Other configuration (e.g., default LLM model name, Vector DB path, paths to prompt/template folders, output directory) SHOULD be loaded from environment variables or a dedicated configuration file (e.g., .env file read using python-dotenv, or a YAML/JSON config file). Access config via a central config object or dictionary throughout the application.
7. Error Handling
Use Python's try...except blocks to catch potential errors, especially around external calls (LLM API, file I/O, subprocess calls, Vector DB operations).
Specific exceptions (e.g., groq.APIError, FileNotFoundError, subprocess.CalledProcessError) should be caught and handled appropriately.
Log errors to a file (debug.log as seen in the code structure) with timestamps and relevant context (e.g., which agent failed, which item ID was being processed).
Critical errors that prevent further processing should be propagated up to the Manager Agent, which should then inform the UI to display an error message to the user.
For non-critical errors (e.g., a single item regeneration failing), log the error and potentially update the item's status in the StructuredCV (e.g., STATUS.ERROR).
8. Testing Strategy
Use pytest for running tests (tests/ folder).
Unit Tests (test_*.py for individual modules):
test_llm.py: Test llm.py wrapper (mocking API calls).
test_vector_db.py, test_vector_store_agent.py: Test Vector DB setup, embedding, and querying (using a temporary in-memory ChromaDB).
test_state_manager.py: Test StructuredCV data model creation, status updates, content updates, and persistence (saving/loading to a temp file).
test_parser_agent.py: Test parsing logic with sample Markdown CVs and JDs, verifying the structure and content of the resulting StructuredCV object.
test_content_writer_agent.py: Test prompt building and LLM call logic (mocking LLM responses), verifying output parsing and cleaning.
test_template_renderer.py: Test rendering logic with sample StructuredCV data and templates.
test_ui.py: Test UI component rendering and basic interaction capture (may require specific Streamlit testing tools or mocking).
Integration Tests (test_orchestrator.py, potentially new files):
Test the workflow sequences managed by the Orchestrator (e.g., Parse -> Research -> Generate cycle), ensuring agents are called correctly and state is updated.
Test the human-in-the-loop feedback loop: Simulate UI actions (Accept, Regenerate, Edit) and verify that the Orchestrator and State Manager update the StructuredCV correctly and trigger regeneration when needed.
Test persistence across sessions (save state, load state, continue tailoring).
Ensure tests cover edge cases (e.g., empty input files, malformed input, LLM returning unexpected format).
Use mocking where necessary (e.g., mocking LLM API calls, Vector DB external calls) to make tests fast and reliable.


==================================================================================


Technical Specification Document (TSD)
Project: CV Tailoring AI Agent (MVP)
Version: 1.1 (Revised - main.py UI, GenAI LLM)
Date: May 1, 2025
Authors: [Your Name/Team Name]
1. Introduction
1.1 Purpose
This Technical Specification Document details the technical design and implementation specifications for the CV Tailoring AI Agent MVP. It serves as a technical blueprint for the development team, elaborating on the architecture and data design outlined in the Software Design Document (SDD) and specifying the technologies, algorithms, interfaces, and configurations at a level sufficient for implementation, reflecting updates to the UI location and core technologies.
1.2 Scope
This document covers the technical specifications for all core components of the MVP, including the specific libraries used, the implementation details of the JSON-compatible StructuredCV data model, the algorithms for parsing diverse text inputs, research using ChromaDB, content generation with Google GenAI, and template-based formatting. It details the Streamlit UI implementation approach within main.py, state persistence mechanisms, configuration management, error handling, and the testing strategy, acknowledging future intentions for a more robust architecture and additional features.


1.3 Definitions, Acronyms, and Abbreviations
(Inherit definitions from SRS and SDD, Sections 1.3)
ChromaDB: The chosen vector database.
Google GenAI: The primary LLM API provider for the MVP.
Jinja2: The chosen templating engine.
Streamlit: The chosen UI framework, implemented within main.py.
UUID: Universally Unique Identifier.
all-MiniLM-L6-v2: The chosen sentence transformer model for embeddings.
xelatex: The chosen LaTeX compiler executable (if LaTeX output).
1.4 References
Software Requirements Specification (SRS) for the CV Tailoring AI Agent (MVP) - Version 1.1
Software Design Document (SDD) for the CV Tailoring AI Agent (MVP) - Version 1.2
aicvgen (Code folder)
aicvgen/main.py (Contains Streamlit UI implementation)
cv_ai_builder_final_template.py (Prototype script)
prompts_folder (LLM prompt files)
Anas_Akhomach-main-template-en.md (Example base CV template structure)
cv_template.md (Example output template)
requirements.txt
1.5 Overview
The rest of this document specifies the technology stack, provides a technical view of the architecture reflecting the UI location, details the technical implementation of the JSON-compatible data structures, describes the technical design of each component including specific algorithms and interfaces with updated technology details, outlines configuration management, error handling, and the testing strategy.
2. Technology Stack
The MVP will be implemented using the following technologies and libraries, as indicated by requirements.txt and the codebase:
Programming Language: Python 3.x
Core Framework/Orchestration: Custom agent classes (agent_base.py), potentially integrating LangGraph for state machine logic (orchestrator.py).
User Interface: Streamlit (main.py).
Large Language Model (LLM) API: Google GenAI (llm.py). Specific models initially: gemini-1.5-pro, gemini-1.0-pro (or configured equivalent). Uses the google-generativeai Python client.
Vector Database: ChromaDB (vector_db.py). Uses the chromadb Python client.
Embedding Model: sentence-transformers library using the all-MiniLM-L6-v2 model.
Templating Engine: Jinja2 (template_renderer.py, prototype).
File Handling: Standard Python os and pathlib.
Serialization: json for state persistence, potentially asdict from dataclasses (state_manager.py, data model file).
Text Processing/Parsing: Standard Python string methods, re (regex), potential Markdown parsing library (markdown-it-py), basic handling for plain text structures. OCR library (e.g., pytesseract) noted as future for image/PDF.
Testing: pytest (tests/ folder).
PDF Compilation (if chosen): subprocess module to invoke external xelatex command.
3. System Architecture (Technical View)
The technical architecture implements the logical architecture described in the SDD.
The Manager Agent (orchestrator.py) will implement the workflow controlling agent execution and interacting with the State Manager.
All agents requiring access to the CV state will interact with a single instance of the State Manager (state_manager.py), which manages the JSON-compatible StructuredCV data.
The UI (main.py) runs on Streamlit's server. The Streamlit code within main.py directly interacts with the backend logic (Manager, State Manager) within the same Python process. User actions captured by Streamlit widgets trigger Python functions that execute the backend logic and update the state, which Streamlit then re-renders.
The Content Writer Agent (content_writer_agent.py) will make API calls to the Google GenAI endpoint using the google-generativeai Python client library wrapped by llm.py.
The Research Agent (research_agent.py) and Vector Store Agent (vector_store_agent.py) will interact with the ChromaDB instance using the chromadb Python client library. The ChromaDB data will persist to disk at a configured path.
Input and output operations, prompt loading (prompts_folder), template loading (cv_template.md, LaTeX template), and state persistence will use standard file system operations, saving/loading state as JSON files.
If LaTeX output is chosen, the Formatter Agent (formatter_agent.py) will use subprocess to call the xelatex command-line executable.
4. Data Structures (Technical Implementation)
4.1 StructuredCV Data Model (JSON-Compatible)


The StructuredCV data model will be implemented using Python dataclasses as outlined in the DDD (Section 2.1), designed for easy conversion to/from JSON.
Serialization: Use dataclasses.asdict() to convert dataclasses to dictionaries and json.dumps() to serialize to a JSON string. Enum values will automatically appear as strings.
Deserialization: Use json.loads() to parse the JSON string back to a dictionary. Custom logic in StructuredCV.from_dict() will be required to recursively reconstruct dataclass instances and correctly convert string values back into ItemStatus and ItemType enums.
File Path: State will be saved to .json files, e.g., data/sessions/{session_id}/state.json.
5. Component Technical Design
(Design details for each agent and key module, referencing the code files)
5.1 Manager Agent (orchestrator.py)
Dependencies: state_manager.py, all functional agent modules, potentially langchain.graph.
Technical Implementation: Implements workflow using Python logic or a state machine framework within orchestrator.py. Handles receiving UI feedback (action type, item_id, potential new content) from callback functions in main.py and uses StateManager methods to update the StructuredCV.
5.2 State Manager (state_manager.py)
Dependencies: data_models.py (where StructuredCV dataclasses are defined), os, json.
Technical Implementation: Methods for navigating and updating the nested StructuredCV object structure based on item_id. Uses json.dumps and json.loads for save/load, calling StructuredCV.to_dict() and StructuredCV.from_dict().
5.3 LLM Wrapper (llm.py)
Dependencies: google.generativeai, os.
Technical Implementation:
API key loading: api_key = os.environ.get("GOOGLE_API_KEY") or similar. Raise error if not found.
Client initialization: genai.configure(api_key=api_key). Potentially add logic to select models based on configuration.
chat_completion method: Takes model_name (e.g., 'gemini-1.5-pro'), messages (list of dicts [{'role': 'user', 'parts': [{'text': '...'}]}] for Google GenAI), and other parameters. Uses genai.GenerativeModel(model_name).generate_content(contents=messages, **kwargs).
Uses try...except to handle potential API errors from google.generativeai.
Returns generated text (response.text).
Design includes potential for wrapper methods or a factory to switch between Google GenAI, Groq, OpenAI clients if needed in the future, presenting a consistent interface to agents.
5.4 Vector Database (vector_db.py) & Vector Store Agent (vector_store_agent.py)


Dependencies: chromadb, sentence_transformers, os.
Technical Implementation:
ChromaDB Initialization: chroma_client = chromadb.PersistentClient(path=config.VECTOR_DB_PATH).
Embedding Model Loading: embedding_model = SentenceTransformer('all-MiniLM-L6-v2').
VectorStoreAgent.add_embeddings: Uses embedding_model.encode() and collection.add() with metadata.
VectorStoreAgent.query: Uses embedding_model.encode() for query and collection.query().
5.5 Research Agent (research_agent.py)
Dependencies: vector_store_agent.py, state_manager.py.
Technical Implementation: Calls VectorStoreAgent.query(). Processes results, likely mapping back to StructuredCV item IDs using metadata. (Technical consideration for future: integrating API calls to web search engines and processing those results).
5.6 Parser Agent (parser_agent.py)
Dependencies: state_manager.py, re, typing, data_models.py. Potentially markdown-it-py.
Technical Implementation:
execute method: Contains logic to process raw text. Uses re for pattern matching (headings, lists) in Markdown/plain text. Creates and populates instances of StructuredCV, Section, Subsection, Item dataclasses. Sets initial statuses.
Handles "start from scratch" by creating a StructuredCV instance with predefined section/subsection structures but empty item lists.
JD parsing extracts requirements using regex or heuristics.
Returns the populated StructuredCV object (JSON-compatible structure).
5.7 Content Writer Agent (content_writer_agent.py)
Dependencies: llm.py, state_manager.py, research_agent.py, os, typing.
Technical Implementation: Calls llm.py.chat_completion() with Google GenAI models. Implements prompt loading, context building (_build_context function handling different data sources and regeneration context), output parsing (may involve checking/extracting JSON if prompt requests it, using json.loads), and cleaning functions (adapted from prototype). Updates StructuredCV via StateManager.
5.8 UI (main.py)
Dependencies: streamlit, state_manager.py, os, typing. Potentially imports functions/classes from other agent modules if calling them directly (though ideally interaction is via Manager/State Manager).
Technical Implementation: The script main.py contains the Streamlit application code.
Uses st.session_state to store the StateManager instance and the root StructuredCV object across reruns. E.g., if 'state_manager' not in st.session_state: st.session_state['state_manager'] = StateManager(...).
Rendering logic iterates through st.session_state['structured_cv'].sections, using st.header, st.subheader, st.container, st.expander.
st.text_area widgets display Item.content with key=f'item_content_{item.id}'. Streamlit automatically handles edits being available in st.session_state under this key on the next rerun.
st.button widgets (key=f'btn_accept_{item.id}', key=f'btn_regen_{item.id}') use on_click callbacks. The callback function reads the potentially edited text from st.session_state[f'item_content_{item.id}'] and calls the relevant backend logic (e.g., a function in main.py that interacts with the Manager Agent instance stored in st.session_state).
5.9 Formatter Agent (formatter_agent.py) & Template Renderer (template_renderer.py)
Dependencies: state_manager.py, template_manager.py, jinja2, os, subprocess (if LaTeX).
Technical Implementation: template_renderer.py uses jinja2.Environment and template.render(). If LaTeX, includes logic to apply an escape_latex filter (porting from prototype) to content before rendering. formatter_agent.py calls subprocess.run for xelatex compilation if output format is PDF.
6. Configuration Management
API keys (Google GenAI) loaded from environment variables (os.environ.get("GOOGLE_API_KEY")).
Other configuration (LLM model names, Vector DB path, prompt/template directories, state file directory) loaded from environment variables or a configuration file (e.g., .env read by python-dotenv) accessed via a dedicated config object/module.
7. Error Handling
Uses Python try...except blocks for external calls (Google GenAI API, file I/O, subprocess, ChromaDB).
Logs errors to debug.log.
Critical errors caught by the Manager Agent, which signals main.py to display user-friendly error messages using st.error.
Non-critical errors during specific item processing (e.g., regeneration fails for one bullet point) logged, and the item's status/metadata in StructuredCV is updated to indicate the issue, which the UI (main.py) can then display.
8. Testing Strategy
Use pytest. Test files (tests/test_*.py) cover:
test_llm.py: Mocking Google GenAI API calls via llm.py.
test_vector_db.py, test_vector_store_agent.py: Testing ChromaDB interactions.
test_state_manager.py: Testing StructuredCV data model manipulation and JSON persistence.
test_parser_agent.py: Testing parsing logic for Markdown/plain text/scratch inputs, verifying output StructuredCV structure.
test_content_writer_agent.py: Testing prompt building, LLM calling (mocked), output parsing/cleaning.
test_template_renderer.py: Testing Jinja2 rendering with sample StructuredCV data.
test_main.py (or dedicated UI test): Testing Streamlit component rendering and callback triggering, verifying interactions with the backend logic/state manager (may require mocking or specific Streamlit testing tools).
Integration tests: Testing sequences of agent calls orchestrated by the Manager and how UI interactions in main.py correctly trigger state changes and subsequent agent calls.