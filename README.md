# AI CV Generator MVP

An intelligent, AI-powered CV tailoring application that creates personalized, job-specific CVs using advanced LLM technology and agentic workflows. Built with Python, Streamlit, and Google's Gemini AI.

## ğŸš€ Features

### Core Functionality
- **Intelligent CV Tailoring**: Advanced AI agents analyze job descriptions and automatically tailor CV content
- **Granular Item Control**: Accept, regenerate, or modify individual CV items (bullet points, qualifications)
- **"Big 10" Skills Extraction**: Automatically identifies and highlights the top 10 most relevant skills
- **Multi-Agent Architecture**: Specialized agents for content writing, research, QA, and formatting
- **Smart Fallbacks**: Robust error handling with graceful degradation when AI services are unavailable

### User Experience
- **Interactive Streamlit UI**: Modern, responsive interface for seamless CV creation
- **Real-time Processing**: Live feedback and progress tracking during CV generation
- **Session Persistence**: Save and resume work across sessions with automatic state management
- **Raw LLM Output Display**: View original AI responses for transparency and debugging
- **User Feedback Integration**: Provide feedback to improve AI-generated content

### Technical Excellence
- **LangGraph Orchestration**: Advanced workflow management with state persistence
- **Secure Logging**: Comprehensive logging with API key protection and PII filtering
- **Pydantic Data Models**: Type-safe data structures with validation
- **Comprehensive Testing**: Unit, integration, and E2E tests with 90%+ coverage
- **Performance Optimized**: CV generation typically completes in under 30 seconds

## Architecture Overview

The application follows a modular, service-oriented architecture with strict separation of concerns:

- **`instance/`**: All runtime-generated data is stored here, including logs, user sessions, vector databases, and output files. This directory is created automatically and is essential for application state. It should be excluded from version control and properly mounted in Docker deployments.
- **`src/`**: Contains the core application logic, organized by feature:
  - **`agents/`**: Specialized AI agents for content generation, analysis, and quality assurance.
  - **`api/`**: External API integrations (e.g., Google Gemini).
  - **`core/`**: Application startup, dependency injection, and core orchestration logic.
  - **`config/`**: Application settings, logging, and environment configuration.
  - **`error_handling/`**: Centralized error classes, boundaries, and agent-specific error handlers.
  - **`frontend/`**: Streamlit user interface components and callbacks.
  - **`integration/`**: High-level facade layer that unifies backend services and workflows.
  - **`models/`**: Pydantic data models with strict type validation and data contracts.
  - **`orchestration/`**: LangGraph workflow definitions and state management.
  - **`services/`**: Business logic for LLM interaction, session management, vector storage, etc.
  - **`templates/`**: Jinja2 templates for content generation and PDF rendering.
  - **`utils/`**: Shared utility functions including CV data manipulation factories.
- **`data/`**: Static configuration data, prompt templates, and persistent vector storage.
- **`tests/`**: Comprehensive testing suite with unit, integration, and end-to-end tests.
- **`docs/`**: Developer and user documentation including deployment guides.
- **`scripts/`**: Deployment and maintenance scripts.

## ğŸ› ï¸ Getting Started

### Prerequisites

- **Python 3.11+**
- **Google Gemini API Key**
- **Git**

### Quick Installation

1. **Clone the repository:**

   ```bash
   git clone <repository-url>
   cd aicvgen
   ```

2. **Create and activate a virtual environment:**

   ```bash
   # Windows
   python -m venv venv
   venv\Scripts\activate

   # macOS/Linux
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install dependencies:**

   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment:**

   Create a `.env` file in the project root and add your Google Gemini API key:

   ```.env
   GEMINI_API_KEY="your_gemini_api_key_here"
   ```

5. **Run the application:**

   ```bash
   streamlit run app.py
   ```

6. **Access the application:**

   Open your browser to `http://localhost:8501`.

### Docker Installation (Alternative)

1. **Build the Docker image:**

   ```bash
   docker build -t aicvgen-app .
   ```

2. **Run the Docker container:**

   ```bash
   docker run -p 8501:8501 --env-file .env -v "%cd%/instance:/app/instance" aicvgen-app
   ```

## ğŸ“– Usage Guide

### Basic Workflow

1. **Start a New Session**
   - Launch the application. A new session is created automatically.
   - Each session is automatically tracked and can be resumed

2. **Input Job Description**
   - Paste the target job description in the text area
   - The AI will automatically analyze requirements and skills

3. **Provide Base CV Content**
   - Upload an existing CV file (PDF, DOCX) or paste text directly
   - The system supports various CV formats and structures

4. **AI Processing**
   - Click "Generate Tailored CV" to start the AI workflow
   - Watch real-time progress as different agents process your content
   - Processing typically takes 15-30 seconds

5. **Review and Refine**
   - **Accept/Regenerate Items**: Click âœ… to accept or ğŸ”„ to regenerate individual bullet points
   - **View Raw AI Output**: Toggle to see original LLM responses for transparency
   - **Provide Feedback**: Add specific feedback to improve regenerated content
   - **Big 10 Skills**: Review and modify the top 10 extracted skills

6. **Export Your CV**
   - Download the final CV in your preferred format
   - Save session state to resume later if needed

### Advanced Features

- **Session Management**: All work is automatically saved and can be resumed
- **Error Recovery**: The system gracefully handles API failures with fallback content
- **Performance Monitoring**: View processing times and system performance metrics
- **Debug Mode**: Enable detailed logging for troubleshooting

## ğŸ”§ Development

### Architecture Overview

The AI CV Generator follows a modern, modular architecture with clear separation of concerns:

- **Multi-Agent System**: Specialized AI agents for different tasks (content writing, research, QA)
- **LangGraph Orchestration**: State-based workflow management with persistence
- **Pydantic Data Models**: Type-safe data structures with validation
- **Streamlit Frontend**: Interactive, real-time user interface
- **Secure Logging**: Comprehensive logging with PII protection

### Project Structure

```
aicvgen/
â”œâ”€â”€ instance/              # Runtime data (logs, sessions, DBs) - gitignored
â”‚   â”œâ”€â”€ logs/              # Application logs with structured format
â”‚   â”œâ”€â”€ sessions/          # User session state persistence
â”‚   â”œâ”€â”€ output/            # Generated CV files and documents
â”‚   â””â”€â”€ vector_db/         # ChromaDB persistent storage
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/            # AI agent implementations
â”‚   â”‚   â”œâ”€â”€ agent_base.py      # Base agent class with common functionality
â”‚   â”‚   â”œâ”€â”€ cleaning_agent.py  # Content cleaning and normalization
â”‚   â”‚   â”œâ”€â”€ cv_analyzer_agent.py  # CV content analysis and optimization
â”‚   â”‚   â”œâ”€â”€ enhanced_content_writer.py  # Advanced content generation
â”‚   â”‚   â”œâ”€â”€ formatter_agent.py  # Document formatting and structure
â”‚   â”‚   â”œâ”€â”€ parser_agent.py     # CV and job description parsing
â”‚   â”‚   â”œâ”€â”€ quality_assurance_agent.py  # Content quality validation
â”‚   â”‚   â”œâ”€â”€ research_agent.py   # Job market research and analysis
â”‚   â”‚   â””â”€â”€ specialized_agents.py  # Agent factory and specialized variants
â”‚   â”œâ”€â”€ api/               # External API integrations
â”‚   â”œâ”€â”€ config/            # Configuration management
â”‚   â”‚   â”œâ”€â”€ environment.py     # Environment variable handling
â”‚   â”‚   â”œâ”€â”€ logging_config.py  # Structured logging configuration
â”‚   â”‚   â””â”€â”€ settings.py        # Application settings and validation
â”‚   â”œâ”€â”€ core/              # Core application logic and orchestration
â”‚   â”‚   â”œâ”€â”€ application_startup.py  # Application initialization sequence
â”‚   â”‚   â”œâ”€â”€ dependency_injection.py  # DI container with lifecycle management
â”‚   â”‚   â””â”€â”€ main.py             # Core application entry point
â”‚   â”œâ”€â”€ error_handling/    # Centralized error management
â”‚   â”‚   â”œâ”€â”€ agent_error_handler.py  # Agent-specific error handling
â”‚   â”‚   â”œâ”€â”€ boundaries.py       # Error boundary definitions
â”‚   â”‚   â”œâ”€â”€ classification.py   # Error classification and routing
â”‚   â”‚   â”œâ”€â”€ exceptions.py       # Custom exception classes
â”‚   â”‚   â””â”€â”€ models.py          # Error metadata models
â”‚   â”œâ”€â”€ frontend/          # Streamlit UI components and callbacks
â”‚   â”‚   â”œâ”€â”€ callbacks.py       # UI event handlers and callbacks
â”‚   â”‚   â””â”€â”€ ui_components.py   # Reusable UI components
â”‚   â”œâ”€â”€ integration/       # High-level integration layer
â”‚   â”‚   â””â”€â”€ enhanced_cv_system.py  # Unified CV generation facade
â”‚   â”œâ”€â”€ models/            # Pydantic data models and schemas
â”‚   â”‚   â”œâ”€â”€ agent_models.py        # Agent execution models
â”‚   â”‚   â”œâ”€â”€ agent_output_models.py # Standardized agent output schemas
â”‚   â”‚   â”œâ”€â”€ data_models.py         # Core business data models
â”‚   â”‚   â””â”€â”€ llm_service_models.py  # LLM service specific models
â”‚   â”œâ”€â”€ orchestration/     # LangGraph workflow definitions
â”‚   â”‚   â”œâ”€â”€ cv_workflow_graph.py   # Main CV generation workflow
â”‚   â”‚   â””â”€â”€ state.py              # Workflow state management
â”‚   â”œâ”€â”€ services/          # Business logic services
â”‚   â”‚   â”œâ”€â”€ llm_service.py         # Enhanced LLM service with caching
â”‚   â”‚   â”œâ”€â”€ llm_cv_parser_service.py  # LLM-based parsing service
â”‚   â”‚   â”œâ”€â”€ session_manager.py     # User session management
â”‚   â”‚   â””â”€â”€ vector_store_service.py  # ChromaDB integration
â”‚   â”œâ”€â”€ templates/         # Jinja2 templates and content management
â”‚   â”‚   â”œâ”€â”€ content_templates.py   # Template management system
â”‚   â”‚   â””â”€â”€ pdf_template.html      # PDF generation template
â”‚   â””â”€â”€ utils/             # Shared utility functions
â”‚       â”œâ”€â”€ cv_data_factory.py     # CV data manipulation utilities
â”‚       â””â”€â”€ decorators.py          # Common decorators and helpers
â”œâ”€â”€ data/                  # Static data and configurations
â”‚   â”œâ”€â”€ prompts/           # LLM prompt templates
â”‚   â”œâ”€â”€ templates/         # Document templates
â”‚   â””â”€â”€ vector_db/         # Vector database storage
â”œâ”€â”€ tests/                 # Comprehensive testing suite
â”‚   â”œâ”€â”€ unit/              # Unit tests for individual components
â”‚   â”œâ”€â”€ integration/       # Integration tests for service interactions
â”‚   â””â”€â”€ e2e/              # End-to-end workflow tests
â”œâ”€â”€ docs/                  # Documentation and development guides
â”‚   â”œâ”€â”€ dev/               # Developer documentation
â”‚   â””â”€â”€ user/             # User guides and API reference
â”œâ”€â”€ scripts/              # Deployment and maintenance scripts
â”‚   â”œâ”€â”€ deploy.sh         # Production deployment script
â”‚   â””â”€â”€ migrate_logs.py   # Log migration utilities
â”œâ”€â”€ logs/                 # Legacy log directory (deprecated)
â”œâ”€â”€ .env.example          # Environment variables template
â”œâ”€â”€ .gitignore            # Git ignore patterns
â”œâ”€â”€ app.py                # Main Streamlit application entry point
â”œâ”€â”€ docker-compose.yml    # Docker Compose configuration
â”œâ”€â”€ Dockerfile            # Container deployment configuration
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ pytest.ini           # Test configuration
â””â”€â”€ README.md             # This documentation
```

### Development Setup

1. **Install development dependencies:**
```bash
pip install -r requirements.txt
pip install pytest pytest-cov black flake8 mypy
```

2. **Run tests:**
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test types
pytest tests/unit/          # Unit tests only
pytest tests/integration/   # Integration tests only
pytest tests/e2e/          # E2E tests only
```

3. **Code quality checks:**
```bash
# Format code
black src/ tests/

# Lint code
flake8 src/ tests/

# Type checking
mypy src/
```

### Key Development Principles

- **Test-Driven Development**: Comprehensive test coverage with unit, integration, and E2E tests
- **Type Safety**: Full Pydantic model validation and mypy type checking
- **Secure by Design**: API key protection, PII filtering, and secure logging
- **Performance First**: Optimized for sub-30-second CV generation
- **Resilient Architecture**: Graceful error handling and fallback mechanisms

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Commit your changes (`git commit -am 'Add your feature'`)
4. Push to the branch (`git push origin feature/your-feature`)
5. Create a new Pull Request
