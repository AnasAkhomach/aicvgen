CV Tailoring AI Agent: Refactoring Plan from Prototype to MVP
Executive Summary
This refactoring plan transforms the existing CV Tailoring AI Agent from a prototype Jupyter notebook into a robust, modular, and maintainable MVP application. The core architectural shift centers on implementing an individual, item-by-item processing strategy for Professional Experience roles and Side Projects to mitigate LLM rate limits (30 RPM/6000 TPM for Groq's deepseek-r1-distill-llama-70b model) while improving user experience through interactive review workflows. The plan establishes a resilient, agent-based architecture with centralized state management and a Streamlit-based UI that enables iterative content generation and review.

Target MVP Architecture
Core Components
Orchestrator (ManagerAgent)
The central controller managing a sophisticated workflow state machine that handles:

Sequential section generation: Key Qualifications → Professional Experience → Side Projects → Executive Summary
Individual item processing loops: For each role/project, generate → display → await user feedback → proceed
State transitions: Managing INITIAL → GENERATED → ACCEPTED/TO_REGENERATE → ACCEPTED cycles
Error recovery: Handling LLM API failures with exponential backoff
Specialized Agents
ContentWriterAgent: Refactored to support single-item generation with raw LLM output capture
ParserAgent: Converts input CV and job descriptions into StructuredCV data model
FormatterAgent: Renders final StructuredCV into professional PDF output
ResearchAgent: (Post-MVP) Vector database integration for enhanced context
Services Layer
LLMService: Centralized API abstraction with exponential backoff for 429 errors
VectorDBService: (Post-MVP) ChromaDB integration for semantic search
Core Data Model
StructuredCV: Central data structure tracking individual item status (GENERATED, ACCEPTED, TO_REGENERATE)
StateManager: Persistent storage and state management across sessions
User Interface
Streamlit Application: Interactive review interface with item-level accept/edit/regenerate controls
Raw LLM Output Display: Transparency feature showing unformatted AI responses
Detailed Refactoring Plan
Phase 1: Foundational Setup
1.1 Project Structure & Configuration
Establish src/ directory structure (already partially complete)
Implement configuration management:
Create config/settings.py for centralized configuration
Move API keys to .env files with python-dotenv
Remove hardcoded model names and API endpoints
Setup centralized logging:
Enhance src/config/logging_config.py
Add structured logging for LLM API calls and rate limit tracking
Implement log rotation and error aggregation
1.2 Dependency Management
Update requirements.txt with version pinning
Add new dependencies: python-dotenv, tenacity (for retry logic)
Verify compatibility with existing Streamlit, ChromaDB, Groq stack
Phase 2: MVP Core Logic & Individual Processing
2.1 Enhanced Data Models
Refactor StructuredCV class in src/core/state_manager.py:
Add individual item tracking for roles and projects
Implement status enums: INITIAL, GENERATED, ACCEPTED, TO_REGENERATE
Add metadata fields for raw LLM output storage
Include "Big 10" skills generation (updating from "Big 6")
2.2 Service Layer Implementation
Create LLMService in src/services/llm.py:
Abstract all Groq API interactions
Implement exponential backoff with tenacity library
Add rate limit monitoring and token counting
Support for multiple models (deepseek-r1-distill-llama-70b, llama-3.3-70b-versatile)
Raw output capture and cleaning pipeline
2.3 Agent Refactoring for Individual Processing
Update ContentWriterAgent in src/agents/content_writer_agent.py:

Modify execute() method to process single items (one role or one project)
Add support for context injection (previous items, job requirements)
Implement raw LLM output capture for UI display
Add retry logic for failed generations
Enhance ParserAgent in src/agents/parser_agent.py:

Parse CV into individual role and project items
Extract static sections (Education, Certifications) for context
Validate input format and provide user feedback
Update FormatterAgent in src/agents/formatter_agent.py:

Generate PDF as primary output format
Support dynamic content appending to existing PDF structure
Maintain professional formatting standards
2.4 Orchestrator Workflow Implementation
Refactor Orchestrator in src/core/orchestrator.py:
Phase 3: Interactive UI Implementation
3.1 Streamlit Interface Enhancement
Update src/core/main.py:
Implement item-by-item review interface
Add "Accept", "Edit", "Regenerate" buttons for each role/project
Display raw LLM output in expandable sections
Show progress indicators for multi-step workflow
Add session state management for workflow persistence
3.2 User Experience Flow
Phase 4: Advanced Features (Post-MVP)
4.1 Vector Database Integration
Implement ResearchAgent with ChromaDB
Add semantic search for relevant CV content matching
Context enhancement for more targeted content generation
4.2 Quality Assurance
Implement QualityAssuranceAgent
Add content validation and consistency checks
Automated formatting and style compliance
4.3 Advanced UI Features
Batch operations for multiple items
Template customization interface
Export options (multiple formats)
Analytics dashboard for generation metrics
Implementation Priorities
Critical Path (Weeks 1-2)
LLMService implementation with rate limit handling
StructuredCV data model updates for individual item tracking
ContentWriterAgent refactoring for single-item processing
Basic Streamlit UI for item-by-item review
Core Features (Weeks 3-4)
Complete Orchestrator workflow implementation
PDF output generation with FormatterAgent
Session persistence and state management
Error handling and recovery mechanisms
Polish & Testing (Week 5)
UI/UX refinements and user testing
Performance optimization and monitoring
Documentation and deployment preparation
Integration testing with real job descriptions
Technical Considerations
Rate Limit Mitigation Strategy
Individual processing reduces token count per request
Exponential backoff handles 429 errors gracefully
Progress persistence prevents work loss during failures
User feedback loops distribute API calls over time
Data Flow Architecture
Input (CV + JD) → Parser → StructuredCV →
  ↓
Key Qualifications Generation →
  ↓
For Each Role: Generate → Review → Accept/Regenerate →
  ↓
For Each Project: Generate → Review → Accept/Regenerate →
  ↓
Executive Summary → Final PDF Output
Error Recovery
Granular failure isolation: Single item failures don't affect entire workflow
State persistence: Resume from last successful step
User notification: Clear error messages and recovery options
Fallback mechanisms: Alternative models or manual input options
This refactoring plan transforms the prototype into a production-ready MVP that addresses the critical challenges of LLM rate limits while providing an intuitive, interactive user experience for CV tailoring.